{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Shallow Benchmark - Bag of Letter sequences Quora Dupes\n",
    "\n",
    "https://www.kaggle.com/selfishgene/shallow-benchmark-0-31675-lb\n",
    "\n",
    "\n",
    "http://stackoverflow.com/questions/8955448/save-load-scipy-sparse-csr-matrix-in-portable-data-format \n",
    "Scipy 1.19 now has scipy.sparse.save_npz and load for serializing sparse matrices (comment in March 2017)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\venv\\py3464\\lib\\site-packages\\ipykernel\\__main__.py:6: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
       "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Should I buy tiago?</td>\n",
       "      <td>What keeps childern active and far from phone ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How can I be a good geologist?</td>\n",
       "      <td>What should I do to be a great geologist?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2  How can I increase the speed of my internet co...   \n",
       "3  Why am I mentally very lonely? How can I solve...   \n",
       "4  Which one dissolve in water quikly sugar, salt...   \n",
       "5  Astrology: I am a Capricorn Sun Cap moon and c...   \n",
       "6                                Should I buy tiago?   \n",
       "7                     How can I be a good geologist?   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  \n",
       "5  I'm a triple Capricorn (Sun, Moon and ascendan...             1  \n",
       "6  What keeps childern active and far from phone ...             0  \n",
       "7          What should I do to be a great geologist?             1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%% load train data\n",
    "\n",
    "trainDF = pd.read_csv('../input/train.csv')\n",
    "trainDF = trainDF.dropna(how=\"any\").reset_index(drop=True)\n",
    "\n",
    "trainDF.ix[:7,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature extraction took 12.97 minutes\n"
     ]
    }
   ],
   "source": [
    "#%% create dictionary and extract BOW features from questions\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "\n",
    "featureExtractionStartTime = time.time()\n",
    "\n",
    "# maxNumFeatures = 300\n",
    "maxNumFeatures = 300000\n",
    "\n",
    "# different parameter set for alexandru:\n",
    "BagOfWordsExtractor = CountVectorizer(max_df=0.999, min_df=50, max_features=maxNumFeatures, \n",
    "                                      analyzer='char', ngram_range=(1,10), \n",
    "                                      binary=True, lowercase=True)\n",
    "\n",
    "# bag of letter sequences (chars)\n",
    "#BagOfWordsExtractor = CountVectorizer(max_df=0.999, min_df=1000, max_features=maxNumFeatures, \n",
    "#                                      analyzer='char', ngram_range=(1,2), \n",
    "#                                      binary=True, lowercase=True)\n",
    "\n",
    "# bag of words\n",
    "#BagOfWordsExtractor = CountVectorizer(max_df=0.999, min_df=10, max_features=maxNumFeatures, \n",
    "#                                      analyzer='word', ngram_range=(1,6), stop_words='english', \n",
    "#                                      binary=True, lowercase=True)\n",
    "\n",
    "BagOfWordsExtractor.fit(pd.concat((trainDF.ix[:,'question1'],trainDF.ix[:,'question2'])).unique())\n",
    "\n",
    "trainQuestion1_BOW_rep = BagOfWordsExtractor.transform(trainDF.ix[:,'question1'])\n",
    "trainQuestion2_BOW_rep = BagOfWordsExtractor.transform(trainDF.ix[:,'question2'])\n",
    "lables = np.array(trainDF.ix[:,'is_duplicate'])\n",
    "\n",
    "featureExtractionDurationInMinutes = (time.time()-featureExtractionStartTime)/60.0\n",
    "print(\"feature extraction took %.2f minutes\" % (featureExtractionDurationInMinutes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\venv\\py3464\\lib\\site-packages\\sklearn\\linear_model\\sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 took 3.42 minutes: accuracy = 0.846, log loss = 0.3518, AUC = 0.919\n",
      "fold 2 took 3.46 minutes: accuracy = 0.844, log loss = 0.3553, AUC = 0.917\n",
      "---------------------------------------------\n",
      "cross validation took 6.91 minutes\n",
      "mean CV: accuracy = 0.845, log loss = 0.3536, AUC = 0.918\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "0#%% prefrom cross validation\n",
    "\n",
    "crossValidationStartTime = time.time()\n",
    "\n",
    "numCVSplits = 8\n",
    "numSplitsToBreakAfter = 2\n",
    "\n",
    "X = -(trainQuestion1_BOW_rep != trainQuestion2_BOW_rep).astype(int)\n",
    "#X = -(trainQuestion1_BOW_rep != trainQuestion2_BOW_rep).astype(int) + \\\n",
    "#      trainQuestion1_BOW_rep.multiply(trainQuestion2_BOW_rep)\n",
    "y = lables\n",
    "\n",
    "logisticRegressor = linear_model.LogisticRegression(C=0.1, solver='sag')\n",
    "\n",
    "logRegAccuracy = []\n",
    "logRegLogLoss = []\n",
    "logRegAUC = []\n",
    "\n",
    "print('---------------------------------------------')\n",
    "stratifiedCV = model_selection.StratifiedKFold(n_splits=numCVSplits, random_state=2)\n",
    "for k, (trainInds, validInds) in enumerate(stratifiedCV.split(X, y)):\n",
    "    foldTrainingStartTime = time.time()\n",
    "\n",
    "    X_train_cv = X[trainInds,:]\n",
    "    X_valid_cv = X[validInds,:]\n",
    "\n",
    "    y_train_cv = y[trainInds]\n",
    "    y_valid_cv = y[validInds]\n",
    "\n",
    "    logisticRegressor.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "    y_train_hat =  logisticRegressor.predict_proba(X_train_cv)[:,1]\n",
    "    y_valid_hat =  logisticRegressor.predict_proba(X_valid_cv)[:,1]\n",
    "\n",
    "    logRegAccuracy.append(accuracy_score(y_valid_cv, y_valid_hat > 0.5))\n",
    "    logRegLogLoss.append(log_loss(y_valid_cv, y_valid_hat))\n",
    "    logRegAUC.append(roc_auc_score(y_valid_cv, y_valid_hat))\n",
    "    \n",
    "    foldTrainingDurationInMinutes = (time.time()-foldTrainingStartTime)/60.0\n",
    "    print('fold %d took %.2f minutes: accuracy = %.3f, log loss = %.4f, AUC = %.3f' % (k+1,\n",
    "             foldTrainingDurationInMinutes, logRegAccuracy[-1],logRegLogLoss[-1],logRegAUC[-1]))\n",
    "\n",
    "    if (k+1) >= numSplitsToBreakAfter:\n",
    "        break\n",
    "\n",
    "\n",
    "crossValidationDurationInMinutes = (time.time()-crossValidationStartTime)/60.0\n",
    "\n",
    "print('---------------------------------------------')\n",
    "print('cross validation took %.2f minutes' % (crossValidationDurationInMinutes))\n",
    "print('mean CV: accuracy = %.3f, log loss = %.4f, AUC = %.3f' % (np.array(logRegAccuracy).mean(),\n",
    "                                                                 np.array(logRegLogLoss).mean(),\n",
    "                                                                 np.array(logRegAUC).mean()))\n",
    "print('---------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.text.Text at 0x16844be0>,\n",
       " <matplotlib.text.Text at 0x81da77b8>,\n",
       " <matplotlib.text.Text at 0x721c45c0>,\n",
       " <matplotlib.text.Text at 0x40bf30b8>,\n",
       " <matplotlib.text.Text at 0x40bf3b70>,\n",
       " <matplotlib.text.Text at 0x40bda668>,\n",
       " <matplotlib.text.Text at 0x40bdf160>,\n",
       " <matplotlib.text.Text at 0x40bdfc18>,\n",
       " <matplotlib.text.Text at 0x279cd710>,\n",
       " <matplotlib.text.Text at 0x279e8208>,\n",
       " <matplotlib.text.Text at 0x279e8cc0>,\n",
       " <matplotlib.text.Text at 0x7f22f7b8>,\n",
       " <matplotlib.text.Text at 0x7f23d2b0>,\n",
       " <matplotlib.text.Text at 0x7f23dd68>,\n",
       " <matplotlib.text.Text at 0x7f214860>,\n",
       " <matplotlib.text.Text at 0x7f24e358>,\n",
       " <matplotlib.text.Text at 0x7f24ee10>,\n",
       " <matplotlib.text.Text at 0x37743908>,\n",
       " <matplotlib.text.Text at 0x37739400>,\n",
       " <matplotlib.text.Text at 0x37739eb8>,\n",
       " <matplotlib.text.Text at 0x377409b0>,\n",
       " <matplotlib.text.Text at 0x3a8114a8>,\n",
       " <matplotlib.text.Text at 0x3a811f60>,\n",
       " <matplotlib.text.Text at 0x3a849a58>,\n",
       " <matplotlib.text.Text at 0x3a847550>,\n",
       " <matplotlib.text.Text at 0x71f5d048>,\n",
       " <matplotlib.text.Text at 0x71f5db00>,\n",
       " <matplotlib.text.Text at 0x71f305f8>,\n",
       " <matplotlib.text.Text at 0x71f3b0f0>,\n",
       " <matplotlib.text.Text at 0x71f3bba8>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9#%% show prediction distribution and \"feature importance\"\n",
    "\n",
    "matplotlib.rcParams['font.size'] = 14\n",
    "matplotlib.rcParams['figure.figsize'] = (10,10)\n",
    "\n",
    "plt.figure(); \n",
    "sns.kdeplot(y_valid_hat[y_valid_cv==0], shade=True, color=\"b\", bw=0.01)\n",
    "sns.kdeplot(y_valid_hat[y_valid_cv==1], shade=True, color=\"g\", bw=0.01)\n",
    "plt.legend(['non duplicate','duplicate'],fontsize=24)\n",
    "plt.title('Validation Accuracy = %.3f, Log Loss = %.4f, AUC = %.3f' %(logRegAccuracy[-1],\n",
    "                                                                      logRegLogLoss[-1],\n",
    "                                                                      logRegAUC[-1]))\n",
    "plt.xlabel('Prediction'); plt.ylabel('Probability Density'); plt.xlim(-0.01,1.01)\n",
    "\n",
    "\n",
    "numFeaturesToShow = 30\n",
    "\n",
    "sortedCoeffients = np.sort(logisticRegressor.coef_)[0]\n",
    "featureNames = BagOfWordsExtractor.get_feature_names()\n",
    "sortedFeatureNames = [featureNames[x] for x in list(np.argsort(logisticRegressor.coef_)[0])]\n",
    "\n",
    "matplotlib.rcParams['font.size'] = 14\n",
    "matplotlib.rcParams['figure.figsize'] = (10,12)\n",
    "\n",
    "plt.figure()\n",
    "plt.suptitle('Feature Importance',fontsize=24)\n",
    "ax = plt.subplot(1,2,1); plt.title('top non duplicate predictors'); \n",
    "plt.xlabel('minus logistic regression coefficient')\n",
    "ax.barh(range(numFeaturesToShow), -sortedCoeffients[:numFeaturesToShow][::-1], align='center'); \n",
    "plt.ylim(-1,numFeaturesToShow); ax.set_yticks(range(numFeaturesToShow)); \n",
    "ax.set_yticklabels(sortedFeatureNames[:numFeaturesToShow][::-1],fontsize=20)\n",
    "\n",
    "ax = plt.subplot(1,2,2); plt.title('top duplicate predictors'); \n",
    "plt.xlabel('logistic regression coefficient')\n",
    "ax.barh(range(numFeaturesToShow), sortedCoeffients[-numFeaturesToShow:], align='center'); \n",
    "plt.ylim(-1,numFeaturesToShow); ax.set_yticks(range(numFeaturesToShow)); \n",
    "ax.set_yticklabels(sortedFeatureNames[-numFeaturesToShow:],fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full training took 4.27 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\venv\\py3464\\lib\\site-packages\\sklearn\\linear_model\\sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#%% train on full training data\n",
    "\n",
    "trainingStartTime = time.time()\n",
    "\n",
    "logisticRegressor = linear_model.LogisticRegression(C=0.1, solver='sag', \n",
    "                                                    class_weight={1: 0.46, 0: 1.32})\n",
    "logisticRegressor.fit(X, y)\n",
    "\n",
    "trainingDurationInMinutes = (time.time()-trainingStartTime)/60.0\n",
    "print('full training took %.2f minutes' % (trainingDurationInMinutes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\venv\\py3464\\lib\\site-packages\\ipykernel\\__main__.py:6: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting on test took 34.01 minutes\n"
     ]
    }
   ],
   "source": [
    "0#%% load test data, extract features and make predictions\n",
    "\n",
    "testPredictionStartTime = time.time()\n",
    "\n",
    "testDF = pd.read_csv('../input/test.csv')\n",
    "testDF.ix[testDF['question1'].isnull(),['question1','question2']] = 'random empty question'\n",
    "testDF.ix[testDF['question2'].isnull(),['question1','question2']] = 'random empty question'\n",
    "\n",
    "testQuestion1_BOW_rep = BagOfWordsExtractor.transform(testDF.ix[:,'question1'])\n",
    "testQuestion2_BOW_rep = BagOfWordsExtractor.transform(testDF.ix[:,'question2'])\n",
    "\n",
    "X_test = -(testQuestion1_BOW_rep != testQuestion2_BOW_rep).astype(int)\n",
    "#X_test = -(testQuestion1_BOW_rep != testQuestion2_BOW_rep).astype(int) + \\\n",
    "#           testQuestion1_BOW_rep.multiply(testQuestion2_BOW_rep)\n",
    "\n",
    "#testPredictions = logisticRegressor.predict_proba(X_test)[:,1]\n",
    "\n",
    "# quick fix to avoid memory errors\n",
    "seperators= [750000,1500000]\n",
    "testPredictions1 = logisticRegressor.predict_proba(X_test[:seperators[0],:])[:,1]\n",
    "testPredictions2 = logisticRegressor.predict_proba(X_test[seperators[0]:seperators[1],:])[:,1]\n",
    "testPredictions3 = logisticRegressor.predict_proba(X_test[seperators[1]:,:])[:,1]\n",
    "testPredictions = np.hstack((testPredictions1,testPredictions2,testPredictions3))\n",
    "\n",
    "matplotlib.rcParams['font.size'] = 14\n",
    "matplotlib.rcParams['figure.figsize'] = (9,9)\n",
    "\n",
    "plt.figure(); \n",
    "plt.subplot(2,1,1); sns.kdeplot(y_valid_hat, shade=True, color=\"b\", bw=0.01); \n",
    "plt.ylabel('Probability Density'); plt.xlim(-0.01,1.01)\n",
    "plt.title('mean valid prediction = ' + str(np.mean(y_valid_hat)))\n",
    "plt.subplot(2,1,2); sns.kdeplot(testPredictions, shade=True, color=\"b\", bw=0.01);\n",
    "plt.xlabel('Prediction'); plt.ylabel('Probability Density'); plt.xlim(-0.01,1.01)\n",
    "plt.title('mean test prediction = ' + str(np.mean(testPredictions)))\n",
    "\n",
    "testPredictionDurationInMinutes = (time.time()-testPredictionStartTime)/60.0\n",
    "print('predicting on test took %.2f minutes' % (testPredictionDurationInMinutes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#%% create a submission\n",
    "\n",
    "# submissionName = 'shallowBenchmark'\n",
    "submissionName = 'LARGE_FILES_ipy_files/shallowBenchmark'\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['test_id'] = testDF['test_id']\n",
    "submission['is_duplicate'] = testPredictions\n",
    "submission.to_csv(submissionName + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "<class 'numpy.ndarray'>\n",
      "(404288, 300000)\n",
      "(404288,)\n"
     ]
    }
   ],
   "source": [
    "# this is mine - Taylor\n",
    "\n",
    "# exporting other objects\n",
    "import scipy\n",
    "\n",
    "print(type(X))  # scipy.sparse.csr.csr_matrix\n",
    "print(type(y))  # numpy.ndarray\n",
    "\n",
    "# save large objects out to binary files\n",
    "# scipy.sparse.save_npz('LARGE_FILES_ipy_files/X.npz', X)\n",
    "# np.save('LARGE_FILES_ipy_files/y.npy', y)\n",
    "\n",
    "# load binary files back into large objects\n",
    "# my_new_X = scipy.sparse.load_npz('LARGE_FILES_ipy_files/X.npz')\n",
    "# my_new_y = np.load('LARGE_FILES_ipy_files/y.npy')\n",
    "\n",
    "\n",
    "print(my_new_X.shape)  # 404288 by 300000 (perfect)\n",
    "print(my_new_y.shape)  # 404288,   (only one dim, perfect)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# same thing but for test\n",
    "\n",
    "print(type(X_test))\n",
    "print(type(testPredictions))\n",
    "\n",
    "# save large test objects out to binary files\n",
    "scipy.sparse.save_npz(\"LARGE_FILES_ipy_files/X_test.npz\", X_test)\n",
    "np.save(\"LARGE_FILES_ipy_files/testPredictions.npy\", testPredictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3464",
   "language": "python",
   "name": "py3464"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
